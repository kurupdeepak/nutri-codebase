# -*- coding: utf-8 -*-
"""Vision Transformer for Nutrition5k regression v1.1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tiYn3aCXOkE2vO2c_FKPP2rvRXSSIfcv

# About
* This notebook contains a quick prototyp to load entire Nutrition5k data, both dish and dish_ingredients are available  
* Callback Creator with default params
* Sample size of 50
* Shows how to upload the directory to tensorboard dev

# Utility & Model Building Components
"""

!pip install tensorflow_addons

"""## CallbackHelper"""

import tensorflow as tf
import tensorflow_addons as tfa
import datetime


class CallbackHelper:
    def __init__(self, base_dir, logs_dir="/logs"):
        self.base_dir = base_dir

        self.logs_base_dir = base_dir + logs_dir

        self.timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")

    def create_callback(self, callback_name=None, experiment=None,  tb_write_images=True, tb_hist_freq=1,
                        es_monitor="val_loss", es_patience=10, lrs_schedule=None, lrs_verbose=0):
        callback = None

        if callback_name == 'MC':
            log_file = self.get_log_file(callback_name, experiment)
            callback = tf.keras.callbacks.ModelCheckpoint(log_file)
            print("Log file used = ", log_file)

        if callback_name == 'TB':
            log_file = self.get_log_file(callback_name, experiment)
            callback = tf.keras.callbacks.TensorBoard(log_dir=log_file,
                                                      write_images=tb_write_images,
                                                      histogram_freq=tb_hist_freq)
            print("Log file used = ", log_file)
            
        if callback_name == 'ES':
            callback = tf.keras.callbacks.EarlyStopping(monitor=es_monitor,
                                                        patience=es_patience)
        if callback_name == 'TQDM':
            callback = tfa.callbacks.TQDMProgressBar()

        if callback_name == 'LRS':
            callback = tf.keras.callbacks.LearningRateScheduler(lrs_schedule, lrs_verbose=lrs_verbose)


        return callback

    def get_log_file(self, callback_name, experiment):
        log_path = self.logs_base_dir + experiment + "/" + self.timestamp + "/" + callback_name
        return log_path

"""## ImageProcessor"""

import numpy as np
import matplotlib.pyplot as plt
import cv2
import random


class ImagePreProcessor:
    def __init__(self, dishes):
        self.dishes = dishes

    @staticmethod
    def crop(img):
        # argwhere will give you the coordinates of every non-zero point
        true_points = np.argwhere(img)
        # take the smallest points and use them as the top left of your crop
        top_left = true_points.min(axis=0)
        # take the largest points and use them as the bottom right of your crop
        bottom_right = true_points.max(axis=0)
        out = img[top_left[0]:bottom_right[0] + 1,  # plus 1 because slice isn't
              top_left[1]:bottom_right[1] + 1]  # inclusive
        return out

    @staticmethod
    def rectangular_mask(dish_path):
        image_bgr = cv2.imread(dish_path)
        mask = np.zeros(image_bgr.shape[:2], dtype="uint8")
        # mask = cv2.rectangle(mask, (0, 480), (180, 580), 255, -1)
        mask = cv2.rectangle(mask, (180, 30), (600, 480), 255, -1)
        masked = cv2.bitwise_or(image_bgr, image_bgr, mask=mask)
        masked = cv2.cvtColor(masked, cv2.COLOR_BGR2RGB)
        return image_bgr, mask, masked

    @staticmethod
    def remove_blue(hsv_image):
        input_image = hsv_image.copy()

        grayscale_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)

        # Convert the BGR image to HSV:
        hsv_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2HSV)

        # Create the HSV range for the blue ink:
        # [128, 255, 255], [90, 50, 70]
        lower_values = np.array([90, 50, 70])
        upper_values = np.array([128, 255, 255])

        # Get binary mask of the blue ink:
        blue_mask = cv2.inRange(hsv_image, lower_values, upper_values)
        # Use a little bit of morphology to clean the mask:
        # Set kernel (structuring element) size:
        kernel_size = 3
        # Set morph operation iterations:
        op_iterations = 1
        # Get the structuring element:
        morph_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))
        # Perform closing:
        blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_CLOSE, morph_kernel, None, None, op_iterations,
                                     cv2.BORDER_REFLECT101)

        # Add the white mask to the grayscale image:
        color_mask = cv2.add(grayscale_image, blue_mask)
        _, binary_image = cv2.threshold(color_mask, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        # cv2.imwrite('bwimage.jpg',binary_image)
        thresh, im_bw = cv2.threshold(binary_image, 210, 230, cv2.THRESH_BINARY)
        kernel = np.ones((1, 1), np.uint8)
        image_final = cv2.dilate(im_bw, kernel=kernel, iterations=1)
        return image_final

    @staticmethod
    def get_final_img(self, image_path, crop_only=False):
        orig_bgr, mask, masked = self.rectangular_mask(image_path)
        cropped_out = self.crop(masked)
        out = []
        if crop_only:
            out.append([orig_bgr, mask, masked, cropped_out, None])
        else:
            rgb = cropped_out.copy()
            hsv = cv2.cvtColor(cropped_out, cv2.COLOR_BGR2HSV)
            imgfinal = self.remove_blue(hsv)
            copy_of = imgfinal.copy()
            # copy_of[copy_of > 0] = 255
            final_img = cv2.bitwise_and(rgb, rgb, mask=copy_of)
            out.append([orig_bgr, mask, masked, cropped_out, final_img])
        return out

    @staticmethod
    def test(self, n=2, crop_only=False):
        index = random.sample(list(np.arange(len(self.dishes))), n)
        img_paths = [self.dishes[i] for i in index]
        out = []
        for i, path in enumerate(img_paths):
            orig_bgr, mask, masked = self.rectangular_mask(path)
            cropped_out = self.crop(masked)
            if crop_only:
                out.append([orig_bgr, mask, masked, cropped_out, None])
            else:
                rgb = cropped_out.copy()
                hsv = cv2.cvtColor(cropped_out, cv2.COLOR_BGR2HSV)
                imgfinal = self.remove_blue(hsv)
                copy_of = imgfinal.copy()
                # copy_of[copy_of > 0] = 255
                final_img = cv2.bitwise_and(rgb, rgb, mask=copy_of)
                out.append([orig_bgr, mask, masked, cropped_out, final_img])
        return out

    @staticmethod
    def display_sample(self, sample, crop_only=False):
        grid = 1
        n = len(sample)
        c = 4 if crop_only else 5
        plt.figure(figsize=(15, 10))
        for i, lst in enumerate(sample):
            img = cv2.cvtColor(lst[0], cv2.COLOR_BGR2RGB)
            plt.subplot(n, c, grid)
            plt.imshow(img)
            plt.title("original")

            grid += 1
            plt.subplot(n, c, grid)
            plt.imshow(lst[1])
            plt.title("mask")

            grid += 1
            plt.subplot(n, c, grid)
            plt.imshow(lst[2])
            plt.title("masked-out")

            grid += 1
            plt.subplot(n, c, grid)
            plt.imshow(lst[3])
            plt.title("cropped")

            if not crop_only:
                grid += 1
                plt.subplot(n, c, grid)
                plt.imshow(lst[4])
                plt.title("final-out")
            grid += 1

"""## VITConfig"""

class VITConfig:
    def __init__(self,
                 image_size=None,
                 patch_size=None,
                 projection_dim=None,
                 num_heads=None,
                 transformer_layers=None,
                 mlp_head_units=None,
                 output_shape=None):
        self.image_size = image_size
        self.patch_size = patch_size
        self.input_shape = (image_size, image_size, 3)  # input image shape
        self.num_patches = (image_size // patch_size) ** 2
        self.projection_dim = projection_dim
        self.num_heads = num_heads
        # Size of the transformer layers
        self.transformer_units = [
            projection_dim * 2,
            projection_dim,
        ]
        self.transformer_layers = transformer_layers
        self.mlp_head_units = mlp_head_units  # Size of the dense layers
        self.output_size = output_shape

    def data_augmentation_layers(self, inputs):
        pass

"""## DatasetUtil"""

import pandas as pd
import os
import matplotlib.pyplot as plt


class DatasetUtil:
    @staticmethod
    def get_top_30_ingredients(dish_ingredients):
        dish_ing_by_count = dish_ingredients[['dish_id', 'name', 'id']] \
            .groupby('dish_id', as_index=False).id.count() \
            .sort_values(by="id", ascending=False)
        return dish_ing_by_count

    @staticmethod
    def check_dir(dish_ids, image_dir):
        # print("Dish Shape",dish_ids.shape)
        df = pd.DataFrame(columns=['dish_id', 'exists'])
        for dish_id in dish_ids:
            # print(dish_images +  id)
            df.loc[len(df.index)] = [dish_id, os.path.exists(image_dir + dish_id)]
        return df

    @staticmethod
    def get_image_path(dish_ids,
                       image_dir,
                       file_name="/rgb.png"):
        # print("Dish Shape",dish_ids)
        images = []
        for dish_id in dish_ids:
            if os.path.exists(image_dir + dish_id):
                images.append({"dish_id": dish_id, "image_path": image_dir + dish_id + file_name})
        df = pd.DataFrame(images, columns=["dish_id", "image_path"])
        return df

    @staticmethod
    def get_rgb_image(dish_ids,
                      image_dir,
                      file_name="/rgb.png"):
        # print("Dish Shape",dish_ids)
        images = []
        for dish_id in dish_ids:
            # print("Types = ",type(dish_images_path),type(dish_id))
            if os.path.exists(image_dir + dish_id):
                images.append({"dish_id": dish_id, "image": plt.imread(image_dir + dish_id + file_name)})
        return images

"""## DatasetConfig"""

class DatasetConfig:
    def __init__(self,
                 base_dir=None,
                 image_dir=None,
                 metadata_dir=None,
                 splits_dir=None):
        self.workspace = base_dir
        self.image_dir = self.workspace + image_dir
        self.metadata_dir = self.workspace + metadata_dir
        self.splits_dir = self.workspace + splits_dir
        self.depth_train_file = "/depth_train_ids.txt"
        self.depth_test_file = "/depth_test_ids.txt"
        self.rgb_train_file = "/rgb_train_ids.txt"
        self.rgb_test_file = "/rgb_test_ids.txt"
        self.dish_cafe1_file = "/dish_metadata_cafe1.csv"
        self.dish_cafe2_file = "/dish_metadata_cafe2.csv"
        self.dish_ingredients_file = '/ingredients_metadata.csv'
        self.dish_id_col = ["dish_id"]

"""## DataLoader"""

import matplotlib.pyplot as plt
import pandas as pd
import random

class DataLoader:
    def __init__(self, data_config: DatasetConfig,
                 debug: bool = False):
        self.rgb_train = None
        self.rgb_test = None
        self.depth_test = None
        self.depth_train = None
        self.test_dish_ids = None
        self.train_dish_ids = None
        self.data_config = data_config
        self.cafe1_dish_info = DishInfo(data_config.metadata_dir + data_config.dish_cafe1_file)
        self.cafe2_dish_info = DishInfo(data_config.metadata_dir + data_config.dish_cafe2_file)
        self.dish_subset = None
        self.dish_ing_subset = None
        cafe_1, cafe1_ing = self.cafe1_dish_info.get_dish_info()
        cafe_2, cafe2_ing = self.cafe2_dish_info.get_dish_info()
        self.LOG_HANDLE = "DataLoader -->"
        if debug:  # Display Information on the loaded files
            print(self.LOG_HANDLE, "Cafe = 1", "*" * 50)
            print(self.LOG_HANDLE, cafe_1.info())
            print(self.LOG_HANDLE, cafe_1.shape)
            print(self.LOG_HANDLE, "Cafe = 1 Dish Ingredients", "*" * 50)
            print(self.LOG_HANDLE, cafe1_ing.info())
            print(self.LOG_HANDLE, cafe1_ing.shape)

            print(self.LOG_HANDLE, "Cafe = 2", "*" * 50)
            print(self.LOG_HANDLE, cafe_2.info())
            print(self.LOG_HANDLE, "Shape = ", cafe_2.shape)
            print(self.LOG_HANDLE, "Cafe = 2 Dish Ingredients", "*" * 50)
            print(self.LOG_HANDLE, cafe2_ing.info())
            print(self.LOG_HANDLE, "Shape = ", cafe2_ing.shape)

        self.dish = pd.concat([cafe_1, cafe_2])
        self.dish_ingredients = pd.concat([cafe1_ing, cafe2_ing])
        print(self.LOG_HANDLE, "Total Dishes", self.dish.shape)
        print(self.LOG_HANDLE, "Total Dish Ingredients", self.dish_ingredients.shape)

        self.__cast_astype_float()

        self.__split_data(debug)

        self.__filter_data_with_images(debug)

    def get_dishes(self, subset=True):
        if subset:
            return self.dish_subset
        return self.dish

    def get_dish_ingredients(self, subset=True):
        if subset:
            return self.dish_ing_subset

        return self.dish_ingredients

    def get_data(self, subset=True):
        if subset:
            return self.dish_subset, self.dish_ing_subset

        return self.dish, self.dish_ingredients

    def get_splits(self):
        return self.train_dish_ids, self.test_dish_ids

    def __split_data(self, debug=False):
        self.depth_train = pd.read_csv(self.data_config.splits_dir + self.data_config.depth_train_file,
                                       header=None,
                                       names=self.data_config.dish_id_col)

        self.depth_test = pd.read_csv(self.data_config.splits_dir + self.data_config.depth_test_file,
                                      header=None,
                                      names=self.data_config.dish_id_col)

        self.rgb_test = pd.read_csv(self.data_config.splits_dir + self.data_config.rgb_test_file,
                                    header=None,
                                    names=self.data_config.dish_id_col)
        self.rgb_train = pd.read_csv(self.data_config.splits_dir + self.data_config.rgb_train_file,
                                     header=None,
                                     names=self.data_config.dish_id_col)
        if debug:
            print(self.LOG_HANDLE, "Depth train split ids shape = ", self.depth_train.shape)
            print(self.LOG_HANDLE, self.depth_train.head())
            print(self.LOG_HANDLE, "RGB train split ids shape = ", self.rgb_train.shape)
            print(self.LOG_HANDLE, self.rgb_train.head())
            print(self.LOG_HANDLE, "Depth test split ids shape = ", self.depth_test.shape)
            print(self.LOG_HANDLE, self.depth_test.head())
            print(self.LOG_HANDLE, "RGB test split ids shape = ", self.rgb_test.shape)
            print(self.LOG_HANDLE, self.rgb_test.head())

        self.train_dish_ids = pd.merge(self.depth_train, self.rgb_train)
        self.test_dish_ids = pd.merge(self.depth_test, self.rgb_test)
        if debug:
            print(self.LOG_HANDLE, "Train Dish Ids = ", self.train_dish_ids.shape)
            print(self.LOG_HANDLE, "Test Dish Ids = ", self.test_dish_ids.shape)

    def __verify_images(self, debug):
        s1 = DatasetUtil.check_dir(self.test_dish_ids.dish_id, self.data_config.image_dir)
        s2 = DatasetUtil.check_dir(self.train_dish_ids.dish_id, self.data_config.image_dir)
        s3 = DatasetUtil.check_dir(self.rgb_train.dish_id, self.data_config.image_dir)
        s4 = DatasetUtil.check_dir(self.rgb_test.dish_id, self.data_config.image_dir)

        if debug:
            print(self.LOG_HANDLE, "Test Dish Ids = ", self.test_dish_ids.shape, s1.shape,
                  s1.exists.value_counts())
            print(self.LOG_HANDLE, "Train Dish Ids = ", self.train_dish_ids.shape, s2.shape,
                  s2.exists.value_counts())
            print(self.LOG_HANDLE, "RGB Train Ids = ", self.rgb_train.shape, s3.shape,
                  s3.exists.value_counts())
            print(self.LOG_HANDLE, "RGB Test Ids = ", self.rgb_test.shape, s4.shape,
                  s4.exists.value_counts())

            i = random.randrange(0, len(self.train_dish_ids))
            # print(self.LOG_HANDLE,i,train_dish_ids.dish_id[i])
            img_path = self.data_config.image_dir + self.train_dish_ids.dish_id[i]
            # print(self.LOG_HANDLE,img_path)
            f, a = plt.subplots(1, 3)

            a[0].imshow(plt.imread(img_path + '/depth_color.png'))
            a[1].imshow(plt.imread(img_path + '/depth_raw.png'))
            a[2].imshow(plt.imread(img_path + '/rgb.png'))

            plt.show()

            i_test = random.randrange(0, len(self.test_dish_ids))
            # print(self.LOG_HANDLE,i,train_dish_ids.dish_id[i])
            img_path = self.data_config.image_dir + self.test_dish_ids.dish_id[i_test]
            # print(self.LOG_HANDLE,img_path)
            f, a = plt.subplots(1, 3)

            a[0].imshow(plt.imread(img_path + '/depth_color.png'))
            a[1].imshow(plt.imread(img_path + '/depth_raw.png'))
            a[2].imshow(plt.imread(img_path + '/rgb.png'))

            plt.show()

        print(self.LOG_HANDLE, "Dish Master", self.dish.shape)
        print(self.LOG_HANDLE, "Dish Ingredients Master", self.dish_ingredients.shape)
        print(self.LOG_HANDLE, "Training Dish Ids", self.train_dish_ids.shape)
        print(self.LOG_HANDLE, "Test Dish Ids", self.test_dish_ids.shape)

    def __cast_astype_float(self):
        self.dish_ingredients['grams'] = self.dish_ingredients.grams.astype("float32")
        self.dish_ingredients['calories'] = self.dish_ingredients.calories.astype("float32")
        self.dish_ingredients['fat'] = self.dish_ingredients.fat.astype("float32")
        self.dish_ingredients['carb'] = self.dish_ingredients.carb.astype("float32")
        self.dish_ingredients['protein'] = self.dish_ingredients.protein.astype("float32")
        self.dish["total_calories"] = self.dish.total_calories.astype("float32")
        self.dish["total_mass"] = self.dish.total_mass.astype("float32")
        self.dish["total_fat"] = self.dish.total_fat.astype("float32")
        self.dish["total_carb"] = self.dish.total_carb.astype("float32")
        self.dish["total_protein"] = self.dish.total_protein.astype("float32")

    def __filter_data_with_images(self, debug):
        if debug:
          print("Going to filter the subset")
        dish_images = DatasetUtil.get_image_path(self.dish.dish_id,self.data_config.image_dir)
        merged_ids = pd.concat([self.train_dish_ids.dish_id, self.test_dish_ids.dish_id])

        tmp = self.dish[self.dish.dish_id.isin(merged_ids)]
        print(tmp.shape)
        
        self.dish_ing_subset = self.dish_ingredients[self.dish_ingredients.dish_id.isin(merged_ids)]
        print(self.dish_ing_subset.shape)

        self.dish_subset = tmp.merge(dish_images)

"""## DishInfo"""

import pandas as pd
import os


class DishInfo:
    def __init__(self, filepath):
        self.file_path = filepath
        lines = self.read_file()
        self.dish_cols = ["dish_id",
                          "total_calories",
                          "total_mass",
                          "total_fat",
                          "total_carb",
                          "total_protein"]

        self.ingredients_col = ["dish_id",
                                "id",
                                "name",
                                "grams",
                                "calories",
                                "fat",
                                "carb",
                                "protein"]
        dish_info = []
        dish_ingredients = []
        s = 6
        step = 7
        line_num = 1
        for line in lines:
            # print(line)
            dish_line = line.split(',')
            dish = dish_line[:s]
            # print(line_num,dish)
            ing_len = len(dish_line[s:])
            tkn = s
            dish_info.append(pd.Series(dish, index=self.dish_cols))
            # print("Going for ingredients",tkn,ing_len)
            while tkn < ing_len:
                row = [dish[0]]
                for c in dish_line[tkn:tkn + step]:
                    row.append(c.strip())
                # print(row)
                dish_ingredients.append(pd.Series(row, index=self.ingredients_col))
                tkn += step
            line_num += 1
            # break
        self.dishes = pd.DataFrame(dish_info, columns=self.dish_cols)
        self.dish_ingredients = pd.DataFrame(dish_ingredients, columns=self.ingredients_col)

    def read_file(self):
        f = open(self.file_path, 'r')
        lines = f.readlines()
        return lines

    def get_dishes(self):
        return self.dishes

    def get_dish_ingredients(self):
        return self.dish_ingredients

    def get_dish_info(self):
        return self.dishes, self.dish_ingredients

"""## MLP"""

import tensorflow as tf


def mlp(x, hidden_units, dropout_rate):
    for units in hidden_units:
        x = tf.keras.layers.Dense(units, activation=tf.nn.gelu)(x)
        x = tf.keras.layers.Dropout(dropout_rate)(x)
    return x

"""## Patches"""

import copy

import tensorflow as tf

class Patches(tf.keras.layers.Layer):

    def __init__(self, vit_config: VITConfig):
        super(Patches, self).__init__()
        self.vit_config = copy.copy(vit_config)

    #     Override function to avoid error while saving model
    def get_config(self):
        config = super().get_config().copy()
        config.update(
            {
                "input_shape": self.vit_config.input_shape,
                "patch_size": self.vit_config.patch_size,
                "num_patches": self.vit_config.num_patches,
                "projection_dim": self.vit_config.projection_dim,
                "num_heads": self.vit_config.num_heads,
                "transformer_units": self.vit_config.transformer_units,
                "transformer_layers": self.vit_config.transformer_layers,
                "mlp_head_units": self.vit_config.mlp_head_units,
            }
        )
        return config

    def call(self, images):
        batch = tf.shape(images)[0]
        patches = tf.image.extract_patches(
            images=images,
            sizes=[1, self.vit_config.patch_size, self.vit_config.patch_size, 1],
            strides=[1, self.vit_config.patch_size, self.vit_config.patch_size, 1],
            rates=[1, 1, 1, 1],
            padding="VALID",
        )
        # return patches
        return tf.reshape(patches, [batch, -1, patches.shape[-1]])

"""## PatchEncoder"""

import copy

import tensorflow as tf

class PatchEncoder(tf.keras.layers.Layer):

    def __init__(self, vit_config: VITConfig):
        super(PatchEncoder, self).__init__()
        self.vit_config = copy.copy(vit_config)
        self.projection = tf.keras.layers.Dense(units=self.vit_config.projection_dim)
        self.position_embedding = tf.keras.layers.Embedding(
            input_dim=self.vit_config.num_patches, output_dim=self.vit_config.projection_dim
        )

    # Override function to avoid error while saving model
    def get_config(self):
        config = super().get_config().copy()
        config.update(
            {
                "input_shape": self.vit_config.input_shape,
                "patch_size": self.vit_config.patch_size,
                "num_patches": self.vit_config.num_patches,
                "projection_dim": self.vit_config.projection_dim,
                "num_heads": self.vit_config.num_heads,
                "transformer_units": self.vit_config.transformer_units,
                "transformer_layers": self.vit_config.transformer_layers,
                "mlp_head_units": self.vit_config.mlp_head_units,
            }
        )
        return config

    def call(self, patch):
        positions = tf.range(start=0, limit=self.vit_config.num_patches, delta=1)
        encoded = self.projection(patch) + self.position_embedding(positions)
        return encoded

"""## ModelCreator"""

import copy

import tensorflow as tf

class ModelCreator:

    @staticmethod
    def create_vit(vit_config: VITConfig):
        inputs = tf.keras.layers.Input(shape=vit_config.input_shape)
        # Data Augmentation Layers
        augmented = vit_config.data_augmentation_layers(inputs)
        # Create patches
        patches = Patches(vit_config)(inputs)
        # Encode patches
        encoded_patches = PatchEncoder(vit_config)(patches)

        # Create multiple layers of the Transformer block.
        for _ in range(vit_config.transformer_layers):
            # Layer normalization 1.
            x1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)
            # Create a multi-head attention layer.
            attention_output = tf.keras.layers.MultiHeadAttention(
                num_heads=vit_config.num_heads, key_dim=vit_config.projection_dim, dropout=0.1
            )(x1, x1)
            # Skip connection 1.
            x2 = tf.keras.layers.Add()([attention_output, encoded_patches])
            # Layer normalization 2.
            x3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x2)
            # MLP
            x3 = mlp(x3, hidden_units=vit_config.transformer_units, dropout_rate=0.1)
            # Skip connection 2.
            encoded_patches = tf.keras.layers.Add()([x3, x2])

        # Create a [batch_size, projection_dim] tensor.
        representation = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)
        representation = tf.keras.layers.Flatten()(representation)
        representation = tf.keras.layers.Dropout(0.3)(representation)
        # Add MLP.
        features = mlp(representation, hidden_units=vit_config.mlp_head_units, dropout_rate=0.3)

        logits = tf.keras.layers.Dense(vit_config.output_size)(features)
        # return Keras model.
        return tf.keras.Model(inputs=inputs, outputs=logits)

"""# Workflow

## Library Import
"""

import pandas as pd
import numpy as np
import tensorflow as tf
import glob2 as glob
import matplotlib.pyplot as plt
import random
import os
import seaborn as sns
import sys
import cv2
import datetime
import tqdm

print(tf.__version__)
print()

# sys.path

workspace = '/content/drive/MyDrive/01_LJMU_UPGRAD/experiments/final-thesis-lab/workspace'
nutrition_codebase = '/notebooks-v1/nutri-codebase'

#!git clone https://github.com/kurupdeepak/nutri-codebase.git '/content/drive/MyDrive/01_LJMU_UPGRAD/experiments/final-thesis-lab/workspace/notebooks-v1/nutri-codebase'

# sys.path.append(workspace + nutrition_codebase)

# sys.path

"""## Configure Path and Environment"""

pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)

import os
os.environ['CUDA_VISIBLE_DEVICES'] = "0"

"""### User Library Import"""

# from nutrition.core.data import DatasetConfig
# from nutrition.core.data import DataLoader
# from nutrition.core.transformer import VITConfig, ModelCreator
# from nutrition.core.transformer.vit import Patches, PatchEncoder,mlp

"""### Dataset Configuration"""

dataset_config = DatasetConfig(base_dir=workspace + '/dataset',
                                image_dir='/realsense_overhead/',
                               metadata_dir='',
                               splits_dir=''
                               )

"""### Load Data """

LOGGER = "data-set-loader -> "
data_loader = DataLoader(data_config=dataset_config, debug=False)
dish_info, dish_ingredients = data_loader.get_data()
train, test = data_loader.get_splits()
print(f"{LOGGER} Dishes from the subset of 3.5k shape = {dish_info.shape}")
print(f"{LOGGER} Dish Ingredient shape = {dish_ingredients.shape}")
print(f"{LOGGER} Already split train ids = {train.shape}")
print(f"{LOGGER} Already split test ids = {test.shape}")

dish_info.info()

dish_info.head()

dish_ingredients.info()

dish_ingredients.head()

"""## Analysis and Visualizations"""







"""## Sample 50 Images for Prototype

### Train/Test Split
"""

SAMPLE_SIZE = 50
sample50_data = dish_info.sample(n=50)
print(sample50_data.shape)

sample50_data.head()

cropped_image_path = '/content/drive/MyDrive/01_LJMU_UPGRAD/experiments/final-thesis-lab/workspace/dataset/processed_overhead/'
sample50_data["cropped_image_path"] = sample50_data.dish_id.apply(lambda x :  cropped_image_path + x + '/cropped.png')

sample50_data.head()

fractions = np.array([0.8, 0.1, 0.1])
# shuffle
df = sample50_data.sample(frac=1) 
# split into 3 parts
train_50, val_50, test_50 = np.array_split(
    df, (fractions[:-1].cumsum() * len(df)).astype(int))
print(train_50.shape)
print(val_50.shape)
print(test_50.shape)
sample50_data = pd.concat([train_50,val_50])
sample50_data.shape

"""## Model -1 """

vit_config_1 = VITConfig(image_size=256,
                           patch_size=16,
                           projection_dim=64,
                           num_heads=8,
                           transformer_layers=4,
                           mlp_head_units=[2048, 1024, 512, 64, 32],
                           output_shape=1)
vit_model_1 = ModelCreator.create_vit(vit_config_1)
print("VIT Model Created, summary below")
print(vit_model_1.summary())

"""## Data Generator

## Normalize total_calories
* Divide it by total_mass of the dish
"""

sample50_data["total_calories_norm"] = round(sample50_data["total_calories"]/sample50_data["total_mass"],2)

sample50_data.info()

generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2,
                                                            horizontal_flip=True,
                                                            vertical_flip=True,
                                                            zoom_range=0.25,
                                                            rotation_range=30,
                                                            brightness_range=[0.6,1.0])

sample50_train_gen  = generator.flow_from_dataframe(dataframe=sample50_data,
                              target_size=(256,256),
                              x_col="cropped_image_path",
                              class_mode ="raw",
                              directory=None,
                              y_col = "total_calories_norm",
                              batch_size=1,
                              shuffle=True,
                              subset="training",
                              seed=123,
                              rescale=1.0/255)
sample50_test_gen  = generator.flow_from_dataframe(dataframe=sample50_data,
                              target_size=(256,256),
                              x_col="cropped_image_path",
                              class_mode ="raw",
                              directory=None,
                              batch_size=1,
                              seed=123,
                              y_col = "total_calories_norm",
                              subset="validation",
                              rescale=1.0/255)



"""## Sample Batch Train Images"""

plt.figure(figsize=(6, 4))
for i in range(2):
  iterator = next(sample50_train_gen)
  image = iterator[0]
  tc = iterator[1]
  image = np.squeeze(image)
  plt.subplot(1,2,i+1)
  plt.imshow(image.astype('uint8'))
  plt.title("Total Calories = " + str(tc))
  plt.axis("off")

"""## Sample Batch Validation Images"""

plt.figure(figsize=(6, 4))
for i in range(2):
  iterator = next(sample50_test_gen)
  image = iterator[0]
  tc = iterator[1]
  image = np.squeeze(image)
  plt.subplot(1,2,i+1)
  plt.imshow(image.astype('uint8'))
  label = round(tc[0] ,2)
  plt.title("Total Calories = " + str(label))
  plt.axis("off")

"""## Sample Patches (16 * 16)"""

patch_size = 16  # Size of the patches to be extracted from the input images
image = next(sample50_train_gen)[0]
image = np.squeeze(image)
plt.figure(figsize=(4, 4))
plt.imshow(image.astype('uint8'))
plt.axis("off")

patches = Patches(vit_config_1)(tf.convert_to_tensor([image]))
print(f"Image size: {vit_config_1.image_size} X {vit_config_1.image_size}")
print(f"Patch size: {vit_config_1.patch_size} X {vit_config_1.patch_size}")
print(f"{patches.shape[1]} patches per image \n{patches.shape[-1]} elements per patch")


n = int(np.sqrt(patches.shape[1]))
plt.figure(figsize=(4, 4))
for i, patch in enumerate(patches[0]):
    ax = plt.subplot(n, n, i + 1)
    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))
    plt.imshow(patch_img.numpy().astype("uint8"))
    plt.axis("off")

"""## Training Model - 1

### Callbacks
"""

callbackHelper = CallbackHelper(workspace)
model_checkpoint = callbackHelper.create_callback(callback_name="MC",experiment="/model-1")
tensorboard_callback = callbackHelper.create_callback(callback_name="TB",experiment="/model-1")
early_stop_callback = callbackHelper.create_callback(callback_name="ES")
tqdm_callback = callbackHelper.create_callback(callback_name="TQDM")
callback_list = [tqdm_callback,model_checkpoint,tensorboard_callback,early_stop_callback,early_stop_callback]

"""### Compile"""

callback_list

vm_lr_1 = 1e-4
vit_model_1.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=vm_lr_1),
              loss="mean_squared_error",
              metrics="mean_absolute_error")

"""### Fit Model"""

batch = 10
num_epochs = 20

hist_model_1 = vit_model_1.fit(
        sample50_train_gen,
        validation_data = sample50_test_gen,
        batch_size=batch,
        epochs=num_epochs,
        callbacks= callback_list
    )

print(STOP HERE)

"""## Tensorboard

### Upload to tensorboard
"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir '/content/drive/MyDrive/01_LJMU_UPGRAD/experiments/final-thesis-lab/workspace/logs/model_1/20221124-091938/tensorboard/'

!tensorboard dev upload --logdir '/content/drive/MyDrive/01_LJMU_UPGRAD/experiments/final-thesis-lab/workspace/logs/model_1/20221124-091938/tensorboard/' --name "Prototype - 50" --description "Training on 50 sample dish images"

hist_model_1

"""### Plot Function"""

plt.plot(hist_model_1.history["loss"], label="train_loss")
plt.plot(hist_model_1.history["val_loss"], label="val_loss")
plt.plot(hist_model_1.history["mean_absolute_error"], label="MAE")
plt.plot(hist_model_1.history["val_mean_absolute_error"], label="VAL MAE")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Train and Validation Losses Over Epochs", fontsize=14)
plt.legend()
plt.grid()
plt.show()
plt.show()

